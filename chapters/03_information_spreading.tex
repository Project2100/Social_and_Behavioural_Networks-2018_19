\chapter[Information spreading]{Information spreading}

\textbf{\textsc{Content note}}: \emph{Most of this chapter is taken from \href{https://github.com/Halolegend94/uni_social_behavioral_networks/blob/master/chapters/ch01-meme-flow.tex}{this repo} by \href{https://github.com/Halolegend94}{Cristian Di Pietrantonio}.}
\vspace{2ex}

On the web, information is published by one or more \emph{sources} and often spreads quickly to other parties. The most popular kind of information that spreads quickly is a meme. From \href{https://en.wikipedia.org/wiki/Meme}{Wikipedia}:

\begin{quote}
	``A meme is an idea, behavior, or style that spreads from person to person within a culture - often with the aim of conveying a particular phenomenon, theme or meaning represented by the meme.''
\end{quote}

In this chapter we are going to define some mathematical models that describes the spread of information. Note that, unlike  the models seen in section [\ref{sec:users-behaviors}], the underlying graphs are static, and do not change over time.

\subsubsection{Push and pull}

Given an undirected graph G, the general spreading model model starts with a single node, the \emph{source} having a specific piece of information. On each time interval:
\begin{itemize}
    \item in the push variant, the vertices possessing the information will replicate and transmit it to a randomly chosen neighbour, regardless of such neighbour being already ``informed'';
    \item in the pull variant, each uninformed vertex randomly chooses a neighbour; if the latter has the information, then it gets replicated and transmittedto the former.
\end{itemize}

An upper bound on the steps is given by the necessary rounds to completely spread the information in the whole graph, which in turn depends on the graph's structure; for example, a star will require much less time than a chain. This model can be useful to choose the best starting vertex, or vertices, for advertising purposes.

\section{The Trace Spreading Model}

In this model for meme flow, nodes can receive or take information from other nodes, enabling the spread of the meme. They can also publish the same meme independently (without ``copying'' each other). Whenever a node publishes information, a timestamp of the event is also available.

At the end, considering a particular meme, all we can see is a bunch of nodes having published with an associated timestamp. What we would like to know is the \emph{social graph} that links these nodes, i.e., who retrieves information from who. Clearly, we can't obtain a perfect reconstruction of the graph, but we can approximate it based on \textit{cascades} or \textit{traces} of the memes.

\begin{defn}[Trace]
    A trace is a sequence of nodes ordered by their timestamp. Usually we write it as:
    \[
        v_1 \to t_1 \to v_2 \to t_2 \to \cdots \to t_{n - 2} \to v_n
    \]
    where $v_i$ are vertices of the social graph and $t_i$ is the time elapsed from when $v_i$ is informed to when $v_{i + 1}$ is informed.
\end{defn}

Define an undirected graph $G = (V, E)$, according to the Trace spreading model: \label{trace-spreading}
\begin{enumerate}
    \item Let $V$ be the set of nodes that holds the information of interest;
    \item Pick a single source of information, chosen \uar;
    \item $e = \{v, v'\} \in E$ iif information propagated from $v$ to $v'$, $v, v' \in V$ (the actual direction is not important, as you will notice later);
    \item Each edge $e = \{v, v'\}$ has a \emph{weight} $w(e)$ sampled \iid{} in $\emph{Exp}(\lambda)$, which models the time needed for the information to propagate from $v$ to $v'$ (in fact, for our purpose, any \textbf{continuous} distribution will do);
    \item Build a trace following the shortest path tree from the source.
\end{enumerate}

From this model and the relative traces, we want to find an efficient algorithm that reconstructs the underlying graph with a certain confidence.

\begin{qst}
    How may traces do we need to reconstruct the graph?
\end{qst}

\section{The First-Edge Algorithm}
We can reconstruct (in most cases) the graph $G=(V, E)$ with high probability with a simple algorithm:
 
\begin{lstlisting}[caption={The first-edge algorithm},label={lst:first-edge}]
FirstEdge($\pi_1, \pi_2, \ldots, \pi_t$)                        // The set of traces
	$E \gets \emptyset$                           // The set of edges in the graph
	for $i = 1, \ldots, t$                       // t = number of traces
		$E \gets E \cup \left\{\left( \pi_i(1), \pi_1(2) \right)\right\}$ // Add only first edge of trace
\end{lstlisting}

Since the algorithm adds one edge for each trace, intuitively we would need as many traces as edges, to find all the edges.

What the algorithm does is simply adding an edge between the first and second node in a trace, for every trace. That is because we can only be sure about the existence of that edge: the first node in a trace is the source (for that trace), since it has the lowest timestamp, the second node, which has the second lowest timestamp, could only get the information from the first node.

For example, consider an execution of the trace spreading model as depicetd in figure \ref{fig:first-edge-ex}. The node $A$, marked with a double line, is chosen as the source, then each edge is assigned a random weight, then the shortest path is followed and each node is labeled with the timestamp at which the meme reaches it. The resulting trace is \texttt{$\pi_1$ = \textbf{A -> C} -> B -> D}.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[auto]
        \path
            (0, 0)        node(a)[draw, circle, minimum size = 2em, label = $0$, double, double distance = 2pt]{A}
            -- (3, -1.5)  node(b)[draw, circle, minimum size = 2em, label = right:$2.7$]{B}
            -- (0, -3)    node(c)[draw, circle, minimum size = 2em, label = below:$1.7$]{C}
            -- (-3, -1.5) node(d)[draw, circle, minimum size = 2em, label = left:$3$]{D}
            (a) edge node {$\pi$}(b)
            (a) edge node {$1.7$}(c)
            (a) edge node {$3$}(d)
            (c) edge node {$1$}(b)
        ;
    \end{tikzpicture}
    \caption{First edge example}
    \label{fig:first-edge-ex}
\end{figure}

The following traces could be:\\
\texttt{$\pi_2$ = \textbf{A -> B} -> D -> C},\\
\texttt{$\pi_3$ = \textbf{C -> B} -> A -> D},\\
\texttt{$\pi_1$ = \textbf{D -> A} -> B -> C},\\
\texttt{$\pi_1$ = \textbf{A -> D} -> B -> C}.

A desirable goal is for the algorithm to give a correct reconstruction of G with minimal error, and to know how many traces it needs to do so. Note new traces are generated by assigning new random weights and choosing a new random source; as such, each trace is completely independent, and identically distributed.

\begin{thm}[First Edge correctness]\label{thm:first-edge}
    Let $G=(V,E)$, $n=|V|$, $\Delta$ = max degree of $G=$, $t=$ number of traces. The output of the algorithm [\ref{lst:first-edge}] will be equal to $E(G)$, i.e., the algorithm will be correct, with probability $\geq 1 - \frac{1}{n^2}$ if $t \geq 2 n \Delta \ln(n)$.
\end{thm}

\begin{lem}
    \[
        \forall \{u, v\} \in E(G)\; \Pr{\text{a random trace } \pi \text{ begins with } \{u, v\}} = \frac{1}{|V| \deg(u)}
    \]
    
\end{lem}

\begin{proof}
    \begin{align*}
        &\ \Pr{\pi \text{ begins with } u, v} & \\
        =&\ \Pr{\text{source is } u \wedge v \text{ is the first neighbor of } u \text{ to be informed}} & \\
        =&\ \Pr{\text{source is } u} \cdot \Pr{\{u, v\} \text{ is the lightest edge incident on } u \mathrel{|} \text{source is } u}&\tag{by Bayes [\ref{eq-bayes}]} \\
        =&\ \frac{1}{n} \cdot \frac{1}{\deg u} &
    \end{align*}

    Note that, in the last step, $\frac{1}{n}$ is implied from the source being chosen \uar, and $\frac{1}{\deg(u)}$ to the fact that each edge outgoing from $u$ has the same probability of being the shortest, since all the weights of these edges are taken from the same probability distribution, and the probability that two edges have the same weight is 0, since the distribution is continuous.
\end{proof}

\begin{lem}
    \[
        \forall \{u, v\} \in E(G) \quad \Pr{\text{a random trace } \pi \text{ begins with } u \to v \text{ or } v \to u} \geq \frac{2}{n \Delta}
    \]
\end{lem}

\begin{proof}
    \begin{align*}
        &\Pr{\pi \text{ begins with } u \to v \text{ or } v \to u}=&\\
        &= \Pr{\pi \text{ begins with } u \to v} + \Pr{\pi \text{ begins with } v \to u} - \Pr{\pi \text{ begins with } u \to v \text{ and } v \to u}&\tag{by [\ref{eq:prob-or}]}\\
        &= \Pr{\pi \text{ begins with } u \to v} + \Pr{\pi \text{ begins with } v \to u} &\tag{since the third probability is 0}\\
        &\frac{1}{\deg(u)} + \frac{1}{\deg(u)} \geq \frac{2}{n \Delta}&\tag{because $\Delta$ is greater or equal than any degree}
    \end{align*}
\end{proof}

Now our aim is to demonstrate that every $\{u, v\} \in E(G)$ appears at the beginning of a trace with positive probability, so that the expected value will be sufficiently high with enough traces.

\begin{lem}
    Let ${u,v} \in E(G)$, and suppose we are given $t \geq 2n \Delta \ln(n)$ traces. Then:
    \[
        \Pr{\text{at least one trace begins with } u \to v \text{ or } v \to u} \geq 1 - \frac{1}{n^4}
    \]
\end{lem}

\begin{proof}
    Let $A_i$ be the event ``\textit{trace $i$ does not begin with $u \to v$, nor it does begin with $v \to u$}''.
    \begin{align*}
        &\Pr{A_1 \wedge A_2 \wedge \ldots \wedge A_t} = &\\
        &=\Pr{u to v \text{ or } v \to u \text{ never appears at the beginning of a trace}}&\\
        &=\prod_{i=0}^{n}\Pr{E_i}&\tag{by [\ref{eq:prob}]}\\
        &\leq \left(1 - \frac{2}{n \Delta}\right)^t&\\
        &\leq \left(e^{-\frac{2}{n \Delta}}\right)^t&\tag{by [\ref{eq:e-x}]}\\
        &\leq \left(e^{-\frac{2}{n \Delta}}\right)^{2n \Delta \ln(n)}& \tag{because $2n \Delta \ln(n)$ is the smallest value that $t$ may assume}\\
        &=e^{-4 \ln(n)} = \frac{1}{n^4}&
    \end{align*}
    Therefore the lemma is demonstrated, since we proved that the probability of the complement of our claim is $1/n^4 = 1 - (1-1/n^4)$.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:first-edge}]
    Let $B_{u,v}$ be the event ``\textit{no trace begins with $u \to v$ or $v \to u$}'' = ``\textit{the algorithm [\ref{lst:first-edge}] doesn't learn about the edge {$u,v$}}''.
    \begin{align*}
        &\Pr{\bigvee_{\{u,v\} \in E(G)} B_{\{u,v\}}}
        \leq \sum_{\{u,v\} \in E(G)} \Pr{B_{\{u,v\}}}
        \leq \sum_{\{u,v\} \in E(G)} n^{-4}
        \leq n^2 \cdot n^{-4} = n^{-2}&
    \end{align*}
    where $n^2$ is an upper bound of $|E(G)|$.\\
    The theorem is shown, since the complement of the bad event is what we were looking for.
\end{proof}
