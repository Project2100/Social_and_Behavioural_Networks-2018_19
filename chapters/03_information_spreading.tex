\chapter[Information spreading]{Information spreading}

\textbf{\textsc{Content note}}: \emph{Most of this chapter is taken from \href{https://github.com/Halolegend94/uni_social_behavioral_networks/blob/master/chapters/ch01-meme-flow.tex}{this repo} by \href{https://github.com/Halolegend94}{Cristian Di Pietrantonio}.}
\vspace{2ex}

On the web, information is published by one or more \emph{sources} and often spreads quickly to other parties. The most popular kind of information that spreads quickly is a meme. From \href{https://en.wikipedia.org/wiki/Meme}{Wikipedia}:

\begin{quote}
	``A meme is an idea, behavior, or style that spreads from person to person within a culture - often with the aim of conveying a particular phenomenon, theme or meaning represented by the meme.''
\end{quote}

In this chapter we are going to define some mathematical models that describes the spread of information. Note that, unlike  the models seen in section \ref{sec:users-behaviors}, the underlying graphs are static, and do not change over time.

\subsubsection{Push and pull}

Given an undirected graph $G$, the general spreading model starts with a single node, the \emph{source} having a specific piece of information. On each time interval:
\begin{itemize}
    \item in the \emph{push} variant, the vertices possessing the information will replicate and transmit it to a randomly chosen neighbour, regardless of such neighbour having already received it;
    \item in the \emph{pull} variant, each uninformed vertex randomly chooses a neighbour; if the latter has the information, then it gets replicated and transmitted to the former.
\end{itemize}

An upper bound on the spreading steps is given by the necessary rounds to completely spread the information in the whole graph, which in turn depends on the graph's structure; for example, a star will require much less time than a chain. This model can be useful to choose the best starting vertices as sources, for advertising purposes.

\section{The Trace Spreading Model}

% Do we mean that it can be viewed either as push or pull, and that it does not matter in the end?
In this information spreading model, nodes can receive or take information from other nodes, enabling the spread of the meme. They can also publish the same meme independently, effectively acting as two separate sources. Whenever a node publishes information, a timestamp of the event is also available.

Once a meme has completely spread, all we can see is a bunch of nodes having published with an associated timestamp. What we would like to know is the \emph{social graph} that links these nodes, or in layman's terms who retrieves information from who. Obtaining a perfect reconstruction of the graph is usually an intractable problem, but a good approximation of it can be efficiently constructed based on \textit{cascades} or \textit{traces} of the memes.

\begin{definition}
    A \emph{trace} is a sequence of nodes ordered by their timestamp. Usually it is written as:
    \[
        v_1 \stackrel{\tau_1}{\longrightarrow} v_2 \stackrel{\tau_2}{\longrightarrow} v_3 \cdots v_{n - 1} \stackrel{\tau_{n - 1}}{\longrightarrow} v_n
    \]
    where $v_i$ are vertices of the social graph and $t_i$ is the time elapsed from when $v_i$ is informed to when $v_{i + 1}$ is informed. Note that this does not imply at all that $v_{i + 1}$ is informed from $v_i$ in any way.
\end{definition}

The model's underlying structure is a simple, directed graph; vertices are the subjects that receive and/or send information/memes, while  each time one total spreading is simulated, an arbitrary weight function on the edges is used. A trace is built by performing the steps described in the algorithm \ref{lst:trace}.

\begin{lstlisting}[caption = {Algorithm for building a trace}, label = {lst:trace}]
algorithm $Trace(G(V, E), S)$
    $r \pickUAR S$
    $w \pickUAR (E \to \expdist(\lambda))$
    $c = $ sequence of all vertices in increasing order of distance from $r$
    return $c$
\end{lstlisting}

For example, consider an execution of the trace spreading model as depicted in figure \ref{fig:first-edge-ex}. The node $A$, marked with a double line, is chosen as the source, then each edge is assigned a random weight, then the shortest path is followed and each node is labeled with the timestamp at which the meme reaches it. The resulting trace is $c = A \stackrel{1.7}{\longrightarrow} C \stackrel{1}{\longrightarrow} B \stackrel{0.3}{\longrightarrow} D$. Note how the trace itself states that $D$ gets informed before $B$: despite this, the vertices are not adjacent; furthermore, with a different weight assignment on the edges, the trace could be very different.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[auto]
        \path
            (0, 0)        node(a)[draw, circle, minimum size = 2em, label = $0$, double, double distance = 2pt]{A}
            -- (3, -1.5)  node(b)[draw, circle, minimum size = 2em, label = right:$2.7$]{B}
            -- (0, -3)    node(c)[draw, circle, minimum size = 2em, label = below:$1.7$]{C}
            -- (-3, -1.5) node(d)[draw, circle, minimum size = 2em, label = left:$3$]{D}
            (a) edge node {$2.9$}(b)
            (a) edge node {$1.7$}(c)
            (a) edge node {$3$}(d)
            (c) edge node {$1$}(b)
        ;
    \end{tikzpicture}
    \caption{First edge example}
    \label{fig:first-edge-ex}
\end{figure}

From here onwards, it is assumed that any node may act as a source: $S = V$. The question is: how many traces do we need to reconstruct the graph reliably enough?

\section{The First-edge Algorithm}
This algorithm, of which steps are provided in \ref{lst:first-edge}, hinges on the simple idea that a trace reliably discovers one edge of the graph, which is the one connecting the source to the first informed vertex after it. Since the algorithm adds one edge for each trace, finding all the edges requires just as many traces.

\begin{lstlisting}[caption = {The First-edge algorithm}, label = {lst:first-edge}]
algorithm $\ferec(C)$                       // The set of traces
    $E \gets \emptyset$                     // The set of edges in the graph
    $\forall c \in C$
        $E \gets E \cup \{(c(1), c(2))\}$   // Add only first edge of trace
    return $E$
\end{lstlisting}

What the algorithm does is simply adding an edge between the first and second node in a trace, for every trace. That is because we can only be sure about the existence of that edge: the first node in a trace is the source (for that trace), since it has the lowest timestamp, the second node, which has the second lowest timestamp, could only get the information from the first node.

A desirable goal is for the algorithm to give a correct reconstruction of G with minimal error, and to know how many traces it needs to do so. Note new traces are generated by assigning new random weights and choosing a new random source; as such, each trace is completely independent, and identically distributed.

In order to get a good bound, some useful lemmata are introduced:

\begin{lemma}\label{lem:feprob} Let $\{u, v\}$ be an edge of a graph $G$, and $c$ be a trace of $G$. Then the probability that such trace begins with $u \to v$ is:
    \[
        \Pr[c \text{ starts with } u \to v] = \frac{1}{|V| \deg(u)}
    \]
    
\end{lemma}

\begin{proof}
    Observe that the source is chosen \uar{}. Also, if a neighboring vertex $v$ is the first to be informed after the source, then the edge connecting them is the lightest of all of the source's neighbours; since the weights are chosen independently, and the continuous property of the distribution makes value collision happen negligibly, this can happen \uar{} too: 

    \begin{align*}
         &\ \Pr[c \text{ starts with } u \to v]                                 & \\
        =&\ \Pr[c(1) = u] \Pr[v = \min_{x \sim c(1)}(w(x)) \knowing c(1) = u]   & \text{(by conditional probability)} \\
        =&\ \frac{1}{n} \cdot \frac{1}{\deg(u)}                                 & \\
    \end{align*}
\end{proof}

\begin{lemma}\label{lem:gen-feprob} A generalization of the previous lemma, using the underlying graph's maximum degree $\Delta$:
    \[
        \forall \{u, v\} \in E(G) \quad \Pr[c \text{ starts with } u \to v \vee c \text{ starts with } v \to u] \geq \frac{2}{n \Delta}
    \]
\end{lemma}

\begin{proof}
    \begin{align*}
            &\ \Pr[c \text{ starts with } u \to v \vee c \text{ starts with } v \to u]      & \\
           =&\ \Pr[c \text{ starts with } u \to v] + \Pr[c \text{ starts with } v \to u]    & \text{(Union of disjoint events)} \\
           =&\ \frac{1}{n} \cdot \frac{1}{\deg(u)} + \frac{1}{n} \cdot \frac{1}{\deg(u)}    & \text{(by lemma \ref{lem:feprob})}\\
        \geq&\ \frac{2}{n \Delta}                                                           & (\forall u \; \Delta \geq \deg(u)) \\
    \end{align*}
\end{proof}


\begin{theorem}[First-edge correctness]\label{thm:first-edge}
    Let $G = (V, E)$, $n = |V|$, $\Delta$ = max degree of $G$, and $C$ a set of $G$'s traces. The output of the First-edge algorithm $\ferec{}$ will be correct with probability no less than $1 - \frac{1}{n^{2(k - 1)}}$ if $\abs{C} \geq k n \Delta \ln(n)$ for some positive constant $k$:
    \[
        \abs{C} \geq k n \Delta \ln(n) \implies \Pr[\ferec(C) = E(G)] \geq 1 - \oneover{n^{2(k - 1)}}
    \]
\end{theorem}

\begin{proof}

    The final goal is to prove that every edge in $G$ appears at the beginning of a trace with positive probability, so that the expected value will be sufficiently high with enough traces.

    \begin{lemma}\label{lem:fesetprob}
        Let $\{u, v\}$ be an edge of a graph $G$, and $C$ be a set of its traces. Then:
        \[
            \abs{C} \geq k n \Delta \ln(n) \implies \Pr[\forall c \in C : c \text{ does not start with } u \to v \wedge c \text{ does not start with } v \to u] \leq \frac{1}{n^{-2 k}}
        \]
    \end{lemma}

    \begin{proof}
        \begin{align*}
             &\ \Pr[\forall c \in C : c \text{ does not start with } u \to v \wedge c \text{ does not start with } v \to u]     & \\
            =&\ \Pr \left[ \bigwedge_{c \in C} c \text{ does not start with } u \to v \wedge c \text{ does not start with } v \to u \right] & \\
            =&\ \prod_{c \in C} \Pr[c \text{ does not start with } u \to v \wedge c \text{ does not start with } v \to u]       & \text{(by [\ref{eq:prob}])} \\
            =&\ \prod_{c \in C} (1 - \Pr[c \text{ starts with } u \to v \vee c \text{ starts with } v \to u])                   & \\
            \leq&\ \left( 1 - \frac{2}{n \Delta} \right)^{\abs{C}}                                                              & \text{(by lemma [\ref{lem:gen-feprob}])}\\
            \leq&\ e^{-\frac{2}{n \Delta} \cdot \abs{C}}                                                                        & \text{(by [\ref{eq:e-x}])} \\
            \leq&\ e^{-\frac{2 \cdot k n \Delta \ln(n)}{n \Delta}}                                                              & \text{(by hypothesis on $\abs{C}$)} \\
            =&\ n^{-2 k}                                                                                                        & \qedhere \\
        \end{align*}
    \end{proof}

    Observe that if an edge is not captured by the algorithm, then there is no trace in $C$ starting with the former's incident edges, in any of the two directions, which is exactly the event encountered in the previous lemma [\ref{lem:fesetprob}]. With it in mind:
    \begin{align*}
            &\ \Pr[\ferec(C) \neq E(G)]         & \\
           =&\ \Pr \left[ \bigvee_{\{u, v\} \in E(G)} \forall c \in C : c \text{ does not start with } u \to v \wedge c \text{ does not start with } v \to u \right] & \\
        \leq&\ \sum_{\{u,v\} \in E(G)} \Pr[\forall c \in C : c \text{ does not start with } u \to v \wedge c \text{ does not start with } v \to u] & \\
            &                                   & \mathllap{\text{(by the \ref{eq:union-bound-gen})}} \\
        \leq&\ \sum_{\{u,v\} \in E(G)} n^{-2 k} & \\
        \leq&\ n^2 \cdot n^{-2 k}               & \mathllap{(|E(G)| \leq |V(G)|^2)} \\
           =&\ n^{-2(1 - k)}                    & \\
    \end{align*}
    
    Notice that this probability can be minimized at will by increasing $c$, which in turn increases the number of required traces.
    
\end{proof}
