\chapter{Introduction}
    
The objectives of the course are:
\begin{enumerate}
    \item to find efficient solutions for social network analysis;
    \item to define models that describe users' behaviour;
    \item to find ways to infer missing data in a social network.
\end{enumerate}

It is desirable that such models adapt concretely to real cases, while still being efficient and understandable. Efficiency is usually measured in memory and execution time, or sometimes in the model's capability of being executed in parallel on more computers, using frameworks such as Pregel or Map-Reduce.


\section{Recurring concepts}

Some equalities and inequalities are used consistently throughout the lectures, they are grouped here for a quick reference list:
\begin{align}
    1 - x \leq&\ e^{-x}                                                 & \label{eq:e-x}                                    \\
    \ln(1 - x) \leq&\ -x                                                & \label{eq:ln-1-x}                                 \\
    \lim_{x \to +\infty} \left(1 - \frac{1}{x}\right)^x =&\ \frac{1}{e} & \label{eq:limit-1/e}                              \\
    \Pr\left[\bigwedge_{i=0}^n A_i\right] =&\ \prod_{i=0}^{n}\Pr[A_i]   & \text{(all } A_i \text{ mutually independent)}    \label{eq:prob} \\
    e^x =&\ \sum_{i = 0}^{\infty} \frac{x^n}{n!}                        & \label{eq:epow}                                   \\
    \Pr[A \wedge B] =&\ \Pr[A] \cdot \Pr[B \knowing A]                  & \tag{Bayes' theorem}                              \label{eq-bayes} \\
    \Pr[A \vee B] =&\ \Pr[A] + \Pr[B] - \Pr[A \wedge B]                 & \label{eq:prob-or}                                \\
    \Pr[A \vee B] \leq&\ \Pr[A] + \Pr[B]                                & \tag{union bound}                                 \label{eq:union-bound} \\
    \Pr\left[\bigvee_{i = 0}^n A_i\right] \leq&\ \sum_{i = 0}^{n}\Pr[A_i]          & \tag{generalized union bound}                     \label{eq:union-bound-gen}
\end{align}

Some terminology notes:

\begin{itemize}
    \item While the words \emph{pick} and \emph{sample} are often used interchangeably, they usually imply different purposes: picking one or more values from a distribution is an action that focuses only on the outcomes themselves, while sampling a number of outcomes has the purpose of extracting a much smaller representative set of outcomes from a much larger one, with the intention of preserving the original distribution, or at least some of its properties;
    \item A \emph{node}, or \emph{vertex}, can be any entity on the web: a blog, a website or a social network profile; in some settings it can also be a person.
\end{itemize}


\section{Probability topics}
    
\begin{definition}[Expected value]\label{def:expected-value}
    Let $X$ be a random variable with a finite number $n$ of finite outcomes $x_1, x_2, \ldots, x_n$ occurring with probabilities $p_1, p_2, \ldots, p_n$ respectively. The expected value of $X$ is
    \begin{equation}
        \expect(X) = \sum_{i = 1}^{n} x_i \cdot p_i.
    \end{equation}
    Note that $\expect(X)$ is called the \textit{expected value} because it means the midpoint where all outcomes, compounded with their weight, contribute to the equilibrium\footnote{This concept works as long as the underlying outcome space possesses the algebraic qualities of an ordered group, such as $\nonneg$}.
\end{definition}

% Law of total expectation

\subsubsection{Pregel framework}

Brief description:
\begin{itemize}
    \item Each node can communicate only with its neighbors;
    \item The computation is asynchronous;
    \item Each node can use few local memory (since there are many nodes);
    \item The nodes of a network (graph) are distributed on many computers, so it's important to group them based on communities to reduce the number of communications among computers, and to accurately choose a threshold between the memory to assign to each node and the number of nodes we want to put into each single machine.
\end{itemize}

\begin{example}[Find connected components of a graph using Pregel]
    Each node contains a unique number at the beginning (an ID), then every one sends its ID to its neighbors, and when a node receives a new number, it replaces its ID with the received one, if it's greater than its own. When the values stop changing, every connected component has the same value; the maximum number of iterations is given by the diameter of the graph.
\end{example}


\subsubsection{Moment-generating functions}
	
Moments of a function, in a mathematical-analytical sense, are quantitative measures related to the shape of the function's graph; for example, a generic function's first moment is its slope (analytically, its first derivative). A moment-generating function is then a function capable of encoding the moments of a random variable in itself. Note that all encoded moments are about 0\footnote{\linkicon \href{https://en.wikipedia.org/wiki/Moment-generating_function}{\textsf{``Moment-generating function --- Wikipedia''}}}.

\begin{definition} Given a random variable $X$, then its moment-generating function is
    \begin{equation}
        M_X(t) = \expect(e^{tX}) \qquad \qquad t \in \real
    \end{equation}
\end{definition}

In order to visualize how moments are encoded into $M_X$, the exponential can be expanded to its power series, by linearity of expectation:

\[
    \expect(e^{tX}) = \sum_{i = 0}^{\infty} \frac{t^i \expect(X^i)}{i!}
\]

Then, computing the n-th derivative, and subsequently setting $t = 0$, the n-th momentum about $0$ of $X$ is obtained.

\subsection{Inequalities on random variables}

These inequalities can be seen an ``internal'' perspective of the notion of \emph{variance}; to give some starting ground, recall how it can be defined:

\[
    \variance(X) = \expect(X - \expect(X))
\]

\subsubsection{Markov's inequality}

\begin{theorem}
    Let $X$ be a non-negative random variable in a sample space $\Omega$, and $a$ an outcome in $\Omega$, then:

    \begin{equation}\label{eq:markov}
        \Pr[X \geq a] \leq \frac{\expect(X)}{a}
    \end{equation}
\end{theorem}

\begin{proof}
    \begin{align*}
        \expect(X) &= \int_{0}^{\infty} x \Pr[X = x]dx    & \text{(Def. of expected value)}         & \\
                   &= \int_{a}^{\infty} x \Pr[X = x]dx + \int_{a}^{\infty} x \Pr[X = x]dx &         & \\
                   &\geq \int_{a}^{\infty} x \Pr[X = x]dx &                                         & \\
                   &\geq \int_{a}^{\infty} a \Pr[X = x]dx & \text{($x \geq a \;\forall x$)}         & \\
                   &= a \Pr[X \geq a]                     & \text{(Def. of cumulative probability)} & \qedhere
    \end{align*}
\end{proof}

Informally, the Markov inequality tells something about an extreme event in a probability distribution of which we know only the expectation: if $\expect(X)$ is small, then it is very unlikely for $X$ to be very large\footnote{\linkicon \href{https://youtu.be/vjYanZ1nsZg}{\textsf{``L18.2 The Markov Inequality'' [MIT OpenCourseWare] --- YouTube}}}\footnote{\linkicon \href{https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals/}{\textsf{Part I: The Fundamentals | Introduction to Probability | MIT OpenCourseWare}}}.

Another formulation of this inequality can be obtained by expressing $a$ as $b \expect(X)$, yielding:
\begin{equation}\label{eq:markov2}
    \Pr[X \geq b \cdot \expect(X)] \leq \frac{1}{b}
\end{equation}


\subsubsection{Chebyshev's inequality}

This inequality can come out as a corollary to Markov's. Let an integrable RV be defined as $(X - \expect(X))^2$ for some other RV $X$, and consider the squared constant $a^2$; using equation \ref{eq:markov} yields:
\[
    \Pr[(X - \expect(X))^2 \geq a^2] \leq \frac{\expect((X - \expect(X))^2)}{a^2}
\]
which can get simplified in two forms, the latter being more popular having $\sigma^2 = \variance(X)$:
\begin{equation}\label{eq:chebyshev2}
    \Pr[\abs{X - \expect(X))} \geq a] \leq \frac{\variance(X)}{a^2}
\end{equation}
\begin{equation}\label{eq:chebyshev}
    \Pr[\abs{X - \expect(X))} \geq a \sigma] \leq \frac{1}{a^2}
\end{equation}


\subsubsection{Chernoff bound}

The \emph{Chernoff bound} is an inequality about probability distributions that are defined as a sum of independent RVs, and allows to control how much said distribution is close to its expected value. For example, it can be used to find how many Facebook users have more than 100 friends: counting all of them would be inefficient, but a good esimate can be obtained by sampling a reasonable number of profiles; such number will be governed by the Chernoff bound. It's important to note that the sample size required to obtain a good approximation also depends on the error we accept to tolerate, and not on the total population.

\begin{definition}[Chernoff bound]
    Let $X$ be the RV obtained by adding together $X_1, \dots, X_n$ Bernoulli RVs that are \iid. Given an outcome $t$, the general statement is:
    \begin{equation}\label{chernoff2}
        \Pr[\abs{X - \expect(X)] \geq t} \leq 2e^{-\frac{t^2}{3n}}
    \end{equation}
\end{definition}

In most cases presented in this course, it will be used on binomial distributions which can be seen as the sum of $n$ \iid{} Bernoulli RVs. Let $X_1, \dots, X_n \in \coin(p)$ be such undelying RVs, with $\Pr[X_i = 1] = p$. Then $X = \sum_{i = 1}^{n} X_i$ and $\expect(X) = np$. Given an error limit $\varepsilon$, and replacing $t$ with $\varepsilon n$, inequality \ref{chernoff2} is rewritten as:

\begin{equation}
    \Pr\left[\abs{\frac{1}{n}\sum_{i = 1}^{n} X_i - p} \geq \varepsilon\right] \leq 2e^{-\frac{1}{3}n\varepsilon^2}
\end{equation}

\begin{example}
    Let $X$ be a RV such that $\expect(X) = \frac{50}{100}$ and define the error margin $\varepsilon = \frac{1}{100}$. The probability that $X \geq \frac{51}{100}$ or $X \leq \frac{49}{100}$ is at most $2e^{-\frac{1}{30000}n}$:
    \begin{align*}
            &\ \Pr\left[X \leq \frac{49}{100} \wedge X \geq \frac{51}{100}\right]                   & \\
           =&\ \Pr\left[X - \half \geq \oneover{100} \wedge X - \half \leq - \oneover{100}\right]   & \\
           =&\ \Pr\left[\abs{X - \half} \geq \oneover{100}\right]                                   & \text{(Recall } \expect(X) = \half) \\
        \leq&\ 2e^{-\oneover{3} n \left(\oneover{100}\right)^2}                                     & \text{(Chernoff bound)} \\
           =&\ 2e^{-\oneover{30000}n}                                                               &
    \end{align*}
\end{example}

\begin{example}
    Let the true expected value be $p = \frac{1}{2}$, and the additive error be $\varepsilon = \sqrt{\frac{\ln(1/\delta)}{n}}$. Then:
    \[
        \Pr[\abs{\text{empirical average} - \text{true expected value}} > \varepsilon] \leq 2e^{-2n\varepsilon^2} = 2e^{-2n \frac{\ln(1/\delta)}{n}} = 2 \delta^2
    \]
    
    Observe that the resulting approximation doesn't depend on the probability $p$.
\end{example}
